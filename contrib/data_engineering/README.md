# data_engineering

The 'data_engineering' project was generated by using the data-engineering template.

## Setup

1. Install the Databricks CLI from https://docs.databricks.com/dev-tools/cli/databricks-cli.html

2. Authenticate to your Databricks workspace, if you have not done so already:
    ```
    $ databricks auth login
    ```

3. We recommend the UV package manager to install project dependencies. It's a drop-in replacement for `pip`.
   UV should be installed as a global package; https://docs.astral.sh/uv/getting-started/installation/ instructions.

4. Install all project dependencies:
   ```
   $ uv sync
   ```

   See the "Running unit tests" below for more on testing.

5. Optionally, install developer tools such as the Databricks extension for Visual Studio Code from
   https://docs.databricks.com/dev-tools/vscode-ext.html. Or the PyCharm plugin from
   https://www.databricks.com/blog/announcing-pycharm-integration-databricks.

## Adding assets such as pipelines and jobs

By default, the data-engineering template does not include any assets.

1. To add an asset, run the `add-asset` script:
   ```
   $ uv run add-asset
   ```

   or, if you don't use UV, use
   
   ```
   $ export TYPE=etl-pipeline
   $ databricks bundle init https://github.com/databricks/bundle-examples --template-dir contrib/templates/data-engineering/assets/$TYPE
   ```

2. Optionally, run all tests on serverless compute after adding an asset:
   ```
   $ uv run test
   ```

## Deploying assets

1. To deploy a development copy of this project, type:
    ```
    $ databricks bundle deploy --target dev
    ```
    (Note that "dev" is the default target, so the `--target` parameter
    is optional here.)

2. Similarly, to deploy a production copy, type:
   ```
   $ databricks bundle deploy --target prod
   ```

3. Use the "summary" comand to review everything that was deployed:
   ```
   $ databricks bundle summary
   ```

4. To run a job or pipeline, use the "run" command:
   ```
   $ databricks bundle run
   ```

## Running unit tests

1. Run tests on a serverless environment using:
   ```
   $ uv run test
   ```

2. Optionally, to run unit tests in a different environment, such as on a cluster,
   please refer to the documentation of DB connect at
   https://docs.databricks.com/en/dev-tools/databricks-connect/python/install.html
