# A sample job for lakeflow_pipelines_python.

resources:
  jobs:
    orchestrate_lakeflow_tpch_etl:
      name: orchestrate_lakeflow_tpch_etl

      trigger:
        # Run this job every day, exactly one day from the last run; see https://docs.databricks.com/api/workspace/jobs/create#trigger
        periodic:
          interval: 1
          unit: DAYS
        pause_status: PAUSED

      #email_notifications:
      #  on_failure:
      #    - your_email@example.com

      # parameters:
      #   - name: catalog
      #     default: ${var.catalog}

      tasks:
        - task_key: refresh_pipeline
          pipeline_task:
            pipeline_id: ${resources.pipelines.pipeline_lakeflow_tpch_etl.id}

      environments:
        - environment_key: default
          spec:
            environment_version: "2"
