resources:
  jobs:
    cluster:
      name: Example to demonstrate using a private wheel package on a job cluster

      tasks:
        - task_key: task
          job_cluster_key: default

          spark_python_task:
            python_file: ../src/main.py

          # Relative local path reference to the private wheel package.
          # This references alone is sufficient to upload it on deployment.
          #
          # It is uploaded to `${workspace.artifact_path}`, which can point to
          # a workspace directory (under `${workspace.bundle_root}`, by default),
          # or a Unity Catalog Volume.
          #
          # This value is automatically rewritten to the fully qualified remote path.
          libraries:
            - whl: ../dist/cowsay-6.1-*.whl

      job_clusters:
        - job_cluster_key: default
          new_cluster:
            spark_version: 15.4.x-scala2.12
            node_type_id: i3.xlarge
            data_security_mode: SINGLE_USER
            num_workers: 0
            spark_conf:
                "spark.databricks.cluster.profile": "singleNode"
                "spark.master": "local[*]"
            custom_tags:
                "ResourceClass": "SingleNode"
