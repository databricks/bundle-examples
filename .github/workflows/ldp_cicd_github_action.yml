name: Databricks pipeline LDP only

on:
  # pull_request:
  #   types: [opened, synchronize]
  # merge_group:
  #   types: [checks_requested]
  push:
    branches: ["main"]

env:
  DATABRICKS_CLIENT_ID: ${{secrets.DATABRICKS_CLIENT_ID}}
  DATABRICKS_CLIENT_SECRET: ${{secrets.DATABRICKS_CLIENT_SECRET}}
  # PROD_DIRECTORY: "/Repos/GA/cicd_w_dabs_ga_demo"

jobs:
  # unit_testing:
  #   name: Databricks Unit testing
  #   runs-on: ubuntu-latest

  #   environment: databricks

  #   steps:
  #     - name: Checkout repository
  #       uses: actions/checkout@v4

  #     - name: Setup Python
  #       uses: actions/setup-python@v5
  #       with:
  #         python-version: "3.10"

  #     - name: Install python dependencies
  #       run: |
  #         python -m pip install --upgrade pip
  #         pip install -r requirements.txt

  #     - name: Setup databricks CLI
  #       uses: databricks/setup-cli@main

  #     - name: Updating databricks repo
  #       run: databricks repos update ${{ env.PROD_DIRECTORY }} --branch ${{ github.ref_name }}
  #       env:
  #         DATABRICKS_BUNDLE_ENV: prod

  #     - name: Run unit tests
  #       run: nutter run "${{ env.PROD_DIRECTORY }}/tests/" --cluster_id $CLUSTER --recursive --junit_report --timeout 900
  #       env:
  #         CLUSTER: ${{ secrets.CLUSTER_ID }}
  #         DATABRICKS_HOST: ${{secrets.DATABRICKS_HOST }}
  #         DATABRICKS_TOKEN: ${{secrets.DATABRICKS_TOKEN }}

  deploy:
    name: Deploy bundle LDP in Prod
    runs-on: ubuntu-latest

    # needs:
    #   - unit_testing

    environment: databricks

    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - name: Setup databricks CLI
        uses: databricks/setup-cli@main

      - name: Deploy bundle
        run: databricks bundle deploy --target prod
        # env:
        #   DATABRICKS_BUNDLE_ENV: prod

  # run_pipeline:
  #   name: Run pipeline update LDP in Prod
  #   runs-on: ubuntu-latest

  #   # Run the "deploy" job before.
  #   needs:
  #     - deploy

  #   environment: databricks

  #   steps:
  #     - name: Checkout repository
  #       uses: actions/checkout@v4

  #     - name: Setup databricks CLI
  #       uses: databricks/setup-cli@main

  #     - name: Run pipeline update
  #       run: databricks bundle run awesome_job --target prod
  #       env:
  #         DATABRICKS_BUNDLE_ENV: prod